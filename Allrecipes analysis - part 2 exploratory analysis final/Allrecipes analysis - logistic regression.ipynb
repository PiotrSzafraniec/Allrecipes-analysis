{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 stars              2.620955\n",
       "pepper               2.594935\n",
       "number_of_reviews    2.575376\n",
       "protein [g]          2.227576\n",
       "garlic               2.017040\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant modules and dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "allrecipes_df = pd.read_csv('allrecipes_data.csv', index_col = [0])\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "types_of_meat = ['chicken', 'beef', 'turkey', 'poultry', 'lamb', 'pork', 'ham', 'bacon', 'sausage', 'salami', 'meat', 'ribs']\n",
    "\n",
    "allrecipes_df['has_meat'] = allrecipes_df['ingredients'].apply(lambda x: any(s.lower() in x for s in types_of_meat))\n",
    "has_meat = allrecipes_df['has_meat']\n",
    "\n",
    "# Remove columns with object datatype\n",
    "data = allrecipes_df.drop(columns = ['name', 'yield', 'nutrition', 'ingredients'])\n",
    "\n",
    "# Check for columns with high number of null values and remove them\n",
    "data.isnull().sum()\n",
    "data = data.drop(columns = ['cook', 'additional', 'cholesterol [mg]'])\n",
    "\n",
    "# Drop all rows with null values in any of the remaining columns\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "# Correlation matrix - mask is applied to remove only one of two highly correlated features in the next step\n",
    "\n",
    "corr_matrix = data.corr().abs()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype = bool))\n",
    "\n",
    "tri_df = corr_matrix.mask(mask)\n",
    "\n",
    "# Dropping features with high correlation\n",
    "\n",
    "to_drop = [c for c in tri_df.columns if any(tri_df[c] >= 0.8)]\n",
    "\n",
    "data.drop(columns = to_drop, inplace = True)\n",
    "\n",
    "# Remove dependent feature (considering it's a boolean)\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Verify VIF values for remaining features - print 5 highest scored features (not including const).\n",
    "# All less than 10 means that features are fine.\n",
    "# If value is over 10 feature is considered to have high multicollinearity and should be removed to avoid overfitting\n",
    "X = add_constant(X)\n",
    "pd.Series([variance_inflation_factor(X.values, i) \n",
    "               for i in range(X.shape[1])], \n",
    "              index=X.columns).sort_values(ascending = False).head(6).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>prep</th>\n",
       "      <th>total</th>\n",
       "      <th>servings</th>\n",
       "      <th>1 stars</th>\n",
       "      <th>recipe_score</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>protein [g]</th>\n",
       "      <th>carbohydrates [g]</th>\n",
       "      <th>fat [g]</th>\n",
       "      <th>...</th>\n",
       "      <th>oregano</th>\n",
       "      <th>thyme</th>\n",
       "      <th>cayenne pepper</th>\n",
       "      <th>sesame</th>\n",
       "      <th>clove</th>\n",
       "      <th>cumin</th>\n",
       "      <th>ginger</th>\n",
       "      <th>basil</th>\n",
       "      <th>paprika</th>\n",
       "      <th>mustard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  prep  total  servings  1 stars  recipe_score  number_of_reviews  \\\n",
       "0  0.000 0.019  0.009     0.042    0.148         0.856              0.235   \n",
       "1  0.000 0.008  0.002     0.017    0.102         0.781              0.116   \n",
       "2  0.000 0.050  0.002     0.160    0.053         0.860              0.060   \n",
       "3  0.000 0.019  0.003     0.025    0.110         0.707              0.050   \n",
       "4  0.000 0.019  0.023     0.025    0.000         0.750              0.001   \n",
       "\n",
       "   protein [g]  carbohydrates [g]  fat [g]  ...  oregano  thyme  \\\n",
       "0        0.336              0.006    0.200  ...    0.000  0.000   \n",
       "1        0.115              0.183    0.040  ...    0.000  0.000   \n",
       "2        0.046              0.310    0.060  ...    0.000  0.000   \n",
       "3        0.288              0.300    0.209  ...    0.000  0.000   \n",
       "4        0.359              0.047    0.229  ...    0.000  0.000   \n",
       "\n",
       "   cayenne pepper  sesame  clove  cumin  ginger  basil  paprika  mustard  \n",
       "0           0.000   0.000  0.000  0.000   0.000  0.000    0.000    0.000  \n",
       "1           0.000   0.000  0.000  0.000   0.000  0.000    0.000    0.000  \n",
       "2           0.000   0.000  0.000  0.000   0.000  0.000    0.000    0.000  \n",
       "3           0.000   0.000  0.000  0.000   0.000  0.000    0.000    0.000  \n",
       "4           0.000   0.000  1.000  0.000   0.000  0.000    0.000    0.000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "columns = X.columns\n",
    "norm = MinMaxScaler()\n",
    "X_norm = norm.fit_transform(X)\n",
    "X_norm = pd.DataFrame(X_norm, columns = columns)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (729, 32)\n",
      "y_train: (729,)\n",
      "X_test: (183, 32)\n",
      "y_test: (183,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "\n",
    "X = X_norm.values\n",
    "y = y.values.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('X_train:', np.shape(X_train))\n",
    "print('y_train:', np.shape(y_train))\n",
    "print('X_test:', np.shape(X_test))\n",
    "print('y_test:', np.shape(y_test))\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print 5 first comparisons between y_pred and y_test\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91 24]\n",
      " [25 43]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "plot_confusion_matrix(classifier, X_test, y_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 73.22%\n",
      "AUC-ROC score value: 0.712\n"
     ]
    }
   ],
   "source": [
    "logreg=accuracy_score(y_test,y_pred)\n",
    "print(f'Model accuracy: {logreg * 100:.2f}%')\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC-ROC score value: {roc_auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       115\n",
      "           1       0.64      0.63      0.64        68\n",
      "\n",
      "    accuracy                           0.73       183\n",
      "   macro avg       0.71      0.71      0.71       183\n",
      "weighted avg       0.73      0.73      0.73       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy of LR: 80.52 %\n",
      "Best Parameter of LR: {'C': 100, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "parameters_lr = [{'penalty':['l1','l2'],'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "grid_search_lr = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters_lr,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_accuracy_lr = grid_search_lr.best_score_\n",
    "best_paramaeter_lr = grid_search_lr.best_params_  \n",
    "print(\"Best Accuracy of LR: {:.2f} %\".format(best_accuracy_lr.mean()*100))\n",
    "print(\"Best Parameter of LR:\", best_paramaeter_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
